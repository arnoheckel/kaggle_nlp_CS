{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/News_Category_Dataset_v3.json', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "data = pd.DataFrame([json.loads(line) for line in lines])\n",
    "\n",
    "# Drop rows with empty short_description\n",
    "data = data.dropna(subset=['short_description'])\n",
    "data = data[data.short_description.apply(lambda x: len(x) > 10)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_examples = \"data/train.json\"\n",
    "with open(path_examples, \"r\") as f:\n",
    "  examples_raw = json.load(f)\n",
    "\n",
    "\n",
    "cohere_examples = []\n",
    "for label, texts in examples_raw.items():\n",
    "    for text in texts:\n",
    "        cohere_examples.append(cohere.ClassifyExample(text=text, label=label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_response(response):\n",
    "    \"\"\"\n",
    "    Response looks like:\n",
    "id='e1ba0613-6314-489d-81f5-79e34a0ba446' \n",
    "classifications=[\n",
    "    ClassifyResponseClassificationsItem(\n",
    "        id='1c5c5c48-6d2c-4faa-959e-41793fd44bad', \n",
    "        input='The role of credit scores in lending decisions is significant.\\n', \n",
    "        prediction='Finance', \n",
    "        predictions=['Finance'], \n",
    "        confidence=0.4602186, \n",
    "        confidences=[0.4602186], \n",
    "        labels={\n",
    "            'Education': ClassifyResponseClassificationsItemLabelsValue(confidence=0.0662585), \n",
    "            'Entertainment': ClassifyResponseClassificationsItemLabelsValue(confidence=0.0324937), \n",
    "            'Environment': ClassifyResponseClassificationsItemLabelsValue(confidence=0.044312477), \n",
    "            'Fashion': ClassifyResponseClassificationsItemLabelsValue(confidence=0.00911254), \n",
    "            'Finance': ClassifyResponseClassificationsItemLabelsValue(confidence=0.4602186), \n",
    "            'Food': ClassifyResponseClassificationsItemLabelsValue(confidence=0.012097831), \n",
    "            'Health': ClassifyResponseClassificationsItemLabelsValue(confidence=0.03673331), \n",
    "            'Politics': ClassifyResponseClassificationsItemLabelsValue(confidence=0.032481745), \n",
    "            'Science': ClassifyResponseClassificationsItemLabelsValue(confidence=0.022289895), \n",
    "            'Sports': ClassifyResponseClassificationsItemLabelsValue(confidence=0.03476186), \n",
    "            'Technology': ClassifyResponseClassificationsItemLabelsValue(confidence=0.22282991), \n",
    "            'Travel': ClassifyResponseClassificationsItemLabelsValue(confidence=0.026409639)\n",
    "        }, \n",
    "        classification_type='single-label')\n",
    "    \n",
    "    __OUTPUT__:\n",
    "        Records with fields: \n",
    "            \"input\": str, \n",
    "            \"prediction\":str, \n",
    "            \"confidence_prediction\":float, \n",
    "            \"labels\":list(str), \n",
    "            \"confidence_labels\":list(float)\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for classification in response.classifications:\n",
    "        data.append({\n",
    "            \"input\": classification.input,\n",
    "            \"prediction\": classification.prediction,\n",
    "            \"confidence_prediction\": classification.confidence,\n",
    "            \"labels\": list(classification.labels.keys()),\n",
    "            \"confidence_labels\": [value.confidence for value in classification.labels.values()]\n",
    "        })\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def cohere_classification(batch_size, rate_limit, checkpointing_folder_path, output_file_path, inputs, cohere_examples):\n",
    "\n",
    "    ## Check if the folder exists\n",
    "    if not os.path.exists(checkpointing_folder_path):\n",
    "        os.makedirs(checkpointing_folder_path)\n",
    "        last_batch = 0\n",
    "    else:\n",
    "        ## Find the last batch\n",
    "        files = os.listdir(checkpointing_folder_path)\n",
    "        last_batch = max([int(file.split(\"_\")[-1].split(\".\")[0]) for file in files])\n",
    "        print(f\"Resuming from batch {last_batch}\")\n",
    "\n",
    "    \n",
    "    ## Initialize the client\n",
    "    co = cohere.Client(os.getenv(\"COHERE_API_KEY\"))\n",
    "\n",
    "    ## Split the inputs into batches\n",
    "    batches_list = [inputs[i:i + batch_size] for i in range(0, len(inputs), batch_size)]\n",
    "\n",
    "    ## Initialize the variables\n",
    "    current_nb_api_calls = 0\n",
    "    start_time = time.time()\n",
    "    file_names = []\n",
    "    i = last_batch\n",
    "\n",
    "    for batch in tqdm(batches_list[last_batch:]):\n",
    "        i += 1\n",
    "        ## API call\n",
    "        response = co.classify(\n",
    "            inputs=batch,\n",
    "            examples=cohere_examples,\n",
    "        )\n",
    "        current_nb_api_calls += 1\n",
    "        ## Parse the response\n",
    "        data = parse_response(response)\n",
    "\n",
    "        ## Save the data\n",
    "        file_path = checkpointing_folder_path + f\"test_batch_{i}.json\"\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(data, f)\n",
    "        file_names.append(file_path)\n",
    "\n",
    "\n",
    "        ## Sleep if rate limit reached\n",
    "        current_rate = 60 * current_nb_api_calls / (time.time() - start_time)\n",
    "        if current_rate >= rate_limit:\n",
    "            time_to_sleep = 60 \n",
    "            print(f\"Rate limit reached, sleeping for {time_to_sleep} seconds\")\n",
    "            time.sleep(time_to_sleep)\n",
    "            current_nb_api_calls = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    ## List files in the checkpointing folder\n",
    "    files = os.listdir(checkpointing_folder_path)\n",
    "\n",
    "    ## Gather all the results\n",
    "    all_results = []\n",
    "    for file in files:\n",
    "        with open(checkpointing_folder_path + file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            all_results += data\n",
    "    \n",
    "    ## Save the results\n",
    "    with open(output_file_path, \"w\") as f:\n",
    "        json.dump(all_results, f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointing_folder_path = \"data/checkpoints/\"\n",
    "output_file_path = \"data/train_from_news_dataset.json\"\n",
    "\n",
    "## Gather all the results\n",
    "all_results = []\n",
    "files = os.listdir(checkpointing_folder_path)\n",
    "for file in files:\n",
    "    with open(checkpointing_folder_path + file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        all_results += data\n",
    "\n",
    "## Save the results\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    json.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49840"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 623/2354 [15:54<44:10,  1.53s/it]   \n"
     ]
    },
    {
     "ename": "TooManyRequestsError",
     "evalue": "status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequestsError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/train_from_news_dataset.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m inputs \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort_description\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mcohere_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_pointing_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcohere_examples\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 29\u001b[0m, in \u001b[0;36mcohere_classification\u001b[0;34m(batch_size, rate_limit, checkpointing_folder_path, output_file_path, inputs, cohere_examples)\u001b[0m\n\u001b[1;32m     27\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m## API call\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcohere_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m current_nb_api_calls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m## Parse the response\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/kaggle_nlp/lib/python3.10/site-packages/cohere/base_client.py:1336\u001b[0m, in \u001b[0;36mBaseCohere.classify\u001b[0;34m(self, inputs, examples, model, preset, truncate, request_options)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(pydantic\u001b[38;5;241m.\u001b[39mparse_obj_as(typing\u001b[38;5;241m.\u001b[39mAny, _response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[0;32m-> 1336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TooManyRequestsError(pydantic\u001b[38;5;241m.\u001b[39mparse_obj_as(typing\u001b[38;5;241m.\u001b[39mAny, _response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalServerError(pydantic\u001b[38;5;241m.\u001b[39mparse_obj_as(typing\u001b[38;5;241m.\u001b[39mAny, _response\u001b[38;5;241m.\u001b[39mjson()))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mTooManyRequestsError\u001b[0m: status_code: 429, body: {'message': \"You are using a Trial key, which is limited to 1000 API calls / month. You can continue to use the Trial key for free or upgrade to a Production key with higher rate limits at 'https://dashboard.cohere.com/api-keys'. Contact us on 'https://discord.gg/XW44jPfYJu' or email us at support@cohere.com with any questions\"}"
     ]
    }
   ],
   "source": [
    "\n",
    "rate_limit = 90\n",
    "batch_size = 80\n",
    "check_pointing_folder_path = \"data/checkpoints/\"\n",
    "output_file_path = \"data/train_from_news_dataset.json\"\n",
    "inputs = data[\"short_description\"].tolist()\n",
    "\n",
    "cohere_classification(batch_size, rate_limit, check_pointing_folder_path, output_file_path, inputs, cohere_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/test_all.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame({\"label\": [d[\"prediction\"] for d in data],\"text\": [d[\"input\"] for d in data]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/test_all.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
